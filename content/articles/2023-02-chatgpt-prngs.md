Title: Are ChatGPT's Random Numbers Actually Random?
Date: 2023-02-19 16:00
Tags: statistics, probability, simulation
slug: chatgpt-prngs

<!-- PELICAN_BEGIN_SUMMARY -->

<figure class="styled"><img class="styled" src="/images/convergence_splash.png" width="642" height="287" title="ChatGPT's random numbers are not always so random." alt="ChatGPT's random numbers are not always so random."><figcaption>ChatGPT's random numbers are not always so random.</figcaption></figure>

Large language models (LLMs) have quickly become part of many people's lives â€” popularized by OpenAI's publicly-available ChatGPT research release, the models excel at just about every textual task. But what about random number generation? LLMs are understandably bad at arithmetic: these are probabilistic language models, not calculators. Still, LLMs like ChatGPT fulfill requests such as "predict the next number in the sequence..." and "give me a random number." So this warrants the question: are the "random" numbers generated by ChatGPT truly random?
<!-- PELICAN_END_SUMMARY -->

{% notebook chatgpt-prngs.ipynb cells[2:-1] %}